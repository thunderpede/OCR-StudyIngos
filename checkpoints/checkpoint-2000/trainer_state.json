{
  "best_metric": 0.0031415873672813177,
  "best_model_checkpoint": "./checkpoints\\checkpoint-2000",
  "epoch": 2.0,
  "eval_steps": 500,
  "global_step": 2000,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.05,
      "grad_norm": 0.6072661876678467,
      "learning_rate": 4.9975e-05,
      "loss": 0.0307,
      "step": 50
    },
    {
      "epoch": 0.1,
      "grad_norm": 0.6346173286437988,
      "learning_rate": 4.995e-05,
      "loss": 0.0196,
      "step": 100
    },
    {
      "epoch": 0.15,
      "grad_norm": 0.49167510867118835,
      "learning_rate": 4.992500000000001e-05,
      "loss": 0.016,
      "step": 150
    },
    {
      "epoch": 0.2,
      "grad_norm": 0.3509403169155121,
      "learning_rate": 4.99e-05,
      "loss": 0.0137,
      "step": 200
    },
    {
      "epoch": 0.25,
      "grad_norm": 0.24372930824756622,
      "learning_rate": 4.9875000000000006e-05,
      "loss": 0.0121,
      "step": 250
    },
    {
      "epoch": 0.3,
      "grad_norm": 0.24577711522579193,
      "learning_rate": 4.9850000000000006e-05,
      "loss": 0.0109,
      "step": 300
    },
    {
      "epoch": 0.35,
      "grad_norm": 0.17366452515125275,
      "learning_rate": 4.9825000000000005e-05,
      "loss": 0.0099,
      "step": 350
    },
    {
      "epoch": 0.4,
      "grad_norm": 0.10982891172170639,
      "learning_rate": 4.9800000000000004e-05,
      "loss": 0.0093,
      "step": 400
    },
    {
      "epoch": 0.45,
      "grad_norm": 0.17554885149002075,
      "learning_rate": 4.9775000000000004e-05,
      "loss": 0.0087,
      "step": 450
    },
    {
      "epoch": 0.5,
      "grad_norm": 0.11076577007770538,
      "learning_rate": 4.975e-05,
      "loss": 0.0079,
      "step": 500
    },
    {
      "epoch": 0.55,
      "grad_norm": 0.16051073372364044,
      "learning_rate": 4.9725e-05,
      "loss": 0.0083,
      "step": 550
    },
    {
      "epoch": 0.6,
      "grad_norm": 0.11184509843587875,
      "learning_rate": 4.97e-05,
      "loss": 0.0075,
      "step": 600
    },
    {
      "epoch": 0.65,
      "grad_norm": 0.12163342535495758,
      "learning_rate": 4.967500000000001e-05,
      "loss": 0.0069,
      "step": 650
    },
    {
      "epoch": 0.7,
      "grad_norm": 0.07464884966611862,
      "learning_rate": 4.965e-05,
      "loss": 0.0071,
      "step": 700
    },
    {
      "epoch": 0.75,
      "grad_norm": 0.10945943742990494,
      "learning_rate": 4.962500000000001e-05,
      "loss": 0.0065,
      "step": 750
    },
    {
      "epoch": 0.8,
      "grad_norm": 0.08007805794477463,
      "learning_rate": 4.96e-05,
      "loss": 0.0063,
      "step": 800
    },
    {
      "epoch": 0.85,
      "grad_norm": 0.15759873390197754,
      "learning_rate": 4.9575000000000006e-05,
      "loss": 0.0062,
      "step": 850
    },
    {
      "epoch": 0.9,
      "grad_norm": 0.16632412374019623,
      "learning_rate": 4.9550000000000005e-05,
      "loss": 0.0058,
      "step": 900
    },
    {
      "epoch": 0.95,
      "grad_norm": 0.060843002051115036,
      "learning_rate": 4.9525000000000004e-05,
      "loss": 0.0057,
      "step": 950
    },
    {
      "epoch": 1.0,
      "grad_norm": 0.09555284678936005,
      "learning_rate": 4.9500000000000004e-05,
      "loss": 0.0059,
      "step": 1000
    },
    {
      "epoch": 1.0,
      "eval_f1": 0.30918065103042663,
      "eval_loss": 0.004171052947640419,
      "eval_mean_iou": 0.7325346823254886,
      "eval_precision": 0.3011152416356491,
      "eval_recall": 0.31769001893422805,
      "eval_runtime": 19.9494,
      "eval_samples_per_second": 50.127,
      "eval_steps_per_second": 12.532,
      "step": 1000
    },
    {
      "epoch": 1.05,
      "grad_norm": 0.12505371868610382,
      "learning_rate": 4.9475e-05,
      "loss": 0.0056,
      "step": 1050
    },
    {
      "epoch": 1.1,
      "grad_norm": 0.14027684926986694,
      "learning_rate": 4.945e-05,
      "loss": 0.0056,
      "step": 1100
    },
    {
      "epoch": 1.15,
      "grad_norm": 0.04818899184465408,
      "learning_rate": 4.9425e-05,
      "loss": 0.0053,
      "step": 1150
    },
    {
      "epoch": 1.2,
      "grad_norm": 0.07706032693386078,
      "learning_rate": 4.94e-05,
      "loss": 0.0054,
      "step": 1200
    },
    {
      "epoch": 1.25,
      "grad_norm": 0.07133658230304718,
      "learning_rate": 4.937500000000001e-05,
      "loss": 0.005,
      "step": 1250
    },
    {
      "epoch": 1.3,
      "grad_norm": 0.11490587145090103,
      "learning_rate": 4.935e-05,
      "loss": 0.0053,
      "step": 1300
    },
    {
      "epoch": 1.35,
      "grad_norm": 0.08701591938734055,
      "learning_rate": 4.9325000000000006e-05,
      "loss": 0.0052,
      "step": 1350
    },
    {
      "epoch": 1.4,
      "grad_norm": 0.08165523409843445,
      "learning_rate": 4.93e-05,
      "loss": 0.0047,
      "step": 1400
    },
    {
      "epoch": 1.45,
      "grad_norm": 0.10824891924858093,
      "learning_rate": 4.9275000000000005e-05,
      "loss": 0.0049,
      "step": 1450
    },
    {
      "epoch": 1.5,
      "grad_norm": 0.09812429547309875,
      "learning_rate": 4.9250000000000004e-05,
      "loss": 0.0052,
      "step": 1500
    },
    {
      "epoch": 1.55,
      "grad_norm": 0.06584513932466507,
      "learning_rate": 4.9225000000000004e-05,
      "loss": 0.0047,
      "step": 1550
    },
    {
      "epoch": 1.6,
      "grad_norm": 0.050117604434490204,
      "learning_rate": 4.92e-05,
      "loss": 0.0048,
      "step": 1600
    },
    {
      "epoch": 1.65,
      "grad_norm": 0.09468996524810791,
      "learning_rate": 4.9175e-05,
      "loss": 0.0045,
      "step": 1650
    },
    {
      "epoch": 1.7,
      "grad_norm": 0.04035024717450142,
      "learning_rate": 4.915e-05,
      "loss": 0.0044,
      "step": 1700
    },
    {
      "epoch": 1.75,
      "grad_norm": 0.042959269136190414,
      "learning_rate": 4.9125e-05,
      "loss": 0.0046,
      "step": 1750
    },
    {
      "epoch": 1.8,
      "grad_norm": 0.06806822121143341,
      "learning_rate": 4.91e-05,
      "loss": 0.004,
      "step": 1800
    },
    {
      "epoch": 1.85,
      "grad_norm": 0.05298401415348053,
      "learning_rate": 4.907500000000001e-05,
      "loss": 0.0042,
      "step": 1850
    },
    {
      "epoch": 1.9,
      "grad_norm": 0.07328721880912781,
      "learning_rate": 4.905e-05,
      "loss": 0.0042,
      "step": 1900
    },
    {
      "epoch": 1.95,
      "grad_norm": 0.02921808697283268,
      "learning_rate": 4.9025000000000006e-05,
      "loss": 0.0041,
      "step": 1950
    },
    {
      "epoch": 2.0,
      "grad_norm": 0.07995299994945526,
      "learning_rate": 4.9e-05,
      "loss": 0.004,
      "step": 2000
    },
    {
      "epoch": 2.0,
      "eval_f1": 0.42844552861661506,
      "eval_loss": 0.0031415873672813177,
      "eval_mean_iou": 0.7580107614045777,
      "eval_precision": 0.4295229033572883,
      "eval_recall": 0.4273735461184166,
      "eval_runtime": 19.5227,
      "eval_samples_per_second": 51.223,
      "eval_steps_per_second": 12.806,
      "step": 2000
    }
  ],
  "logging_steps": 50,
  "max_steps": 100000,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 100,
  "save_steps": 500,
  "stateful_callbacks": {
    "EarlyStoppingCallback": {
      "args": {
        "early_stopping_patience": 5,
        "early_stopping_threshold": 0.0
      },
      "attributes": {
        "early_stopping_patience_counter": 0
      }
    },
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 1.40223644172288e+17,
  "train_batch_size": 4,
  "trial_name": null,
  "trial_params": null
}
